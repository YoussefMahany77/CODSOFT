{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hZU4QrDOI5Z",
        "outputId": "2b5de8d1-d0f3-40a6-8f6d-4975b4d6578f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ2tfOHmCtZ5",
        "outputId": "705c5539-2c99-4de4-b372-a689f5b3332a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-22fa526b93aa>:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X = np.zeros((len(sequences), seq_length, num_chars), dtype=np.bool)\n",
            "<ipython-input-3-22fa526b93aa>:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sequences), num_chars), dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 6s 493ms/step - loss: 3.8144\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 2s 821ms/step - loss: 3.7374\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 3s 872ms/step - loss: 3.4454\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 2s 465ms/step - loss: 3.2969\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 2s 504ms/step - loss: 3.1929\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 3.1739\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 2s 473ms/step - loss: 3.1426\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 2s 475ms/step - loss: 3.1285\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 2s 475ms/step - loss: 3.1285\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 2s 768ms/step - loss: 3.1252\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 3s 865ms/step - loss: 3.1215\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 2s 485ms/step - loss: 3.1176\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 2s 476ms/step - loss: 3.1129\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 2s 477ms/step - loss: 3.1121\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 2s 496ms/step - loss: 3.1101\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 3.1097\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 2s 481ms/step - loss: 3.1107\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 2s 724ms/step - loss: 3.1085\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 3s 892ms/step - loss: 3.1079\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 2s 468ms/step - loss: 3.1073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "text = \"The IAM database contains 13,353 images of handwritten lines of text created by 657 writers.The texts those writers transcribed are from the Lancaster-Oslo/Bergen Corpus of British English. It includes contributions from 657 writers making a total of 1,539 handwritten pages comprising of 115,320 words and is categorized as part of modern collection. The database is labeled at the sentence, line, and word levels.\"\n",
        "\n",
        "chars = sorted(set(text))\n",
        "num_chars = len(chars)\n",
        "\n",
        "char_to_idx = {char: i for i, char in enumerate(chars)}\n",
        "idx_to_char = {i: char for i, char in enumerate(chars)}\n",
        "\n",
        "seq_length = 100\n",
        "sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - seq_length, 1):\n",
        "    sequences.append(text[i:i + seq_length])\n",
        "    next_chars.append(text[i + seq_length])\n",
        "X = np.zeros((len(sequences), seq_length, num_chars), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), num_chars), dtype=np.bool)\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        X[i, t, char_to_idx[char]] = 1\n",
        "    y[i, char_to_idx[next_chars[i]]] = 1\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.LSTM(128, input_shape=(seq_length, num_chars), return_sequences=True),\n",
        "    keras.layers.LSTM(128),\n",
        "    keras.layers.Dense(num_chars, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.fit(X, y, epochs=20, batch_size=128)\n",
        "\n",
        "model.save('text_generation_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAi0ulroGu6Q",
        "outputId": "0a4e2022-9793-4463-83e8-79803eeab046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The IAM database containso5hsosfe76ao1torfncatn onsataf  eateu5e ni auno3a,cnso eoetbc7wop eaad fo-cBoaaases .ghtsl a/aeoumstrsf.ea Botyrsh,t se i  a rscwarho.wcitaia5srswn wpI1Ig ennsrpg.0 fundoer7If  sk C  Be 3aag1eci,mm oe\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = keras.models.load_model('text_generation_model.h5')\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(model, seed_text, length=200):\n",
        "    generated_text = seed_text\n",
        "    for i in range(length):\n",
        "        x = np.zeros((1, seq_length, num_chars))\n",
        "        for t, char in enumerate(seed_text):\n",
        "            x[0, t, char_to_idx[char]] = 1\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_char = idx_to_char[np.random.choice(num_chars, p=preds)]\n",
        "        generated_text += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "    return generated_text\n",
        "\n",
        "# Generate handwritten-like text\n",
        "seed_text = \"The IAM database contains\"\n",
        "generated_text = generate_text(loaded_model, seed_text, length=200)\n",
        "\n",
        "print(generated_text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}